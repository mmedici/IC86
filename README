The code is organized into three main parts: processing, cutting, and plotting (which are sorted into directories). Each directory contains a one or more executable scripts (process.py, cut.py, comparison.py, and interpolation.py), as well as modules contain the functions used within the executables.

The input and output files for the executable scripts are provided as command line arguments, so it should be easy to automate workflows using shell scripts (several examples are provided). For an explanation of the command line usage, call the script with the -h flag. For example,

$ python process.py -h

To view the documentation for a file, call the pydoc command on it. Eg.

$ pydoc geometry.py
... lots of wonderful documentation

What follows is a general overview of the main executable files.

Processing: Before we do the main cuts on the files, some basic filtering, reconstruction, and calculations must be done. process.py takes an I3 file with its GCD, applies this processing, and writes the output to another I3 file. Here is a general overview of the script:

  o Get the command line arguments and open the files

  o Frame Filtering

    Some basic frame filters (these are held constant). They are:

    in_ice - Check that sub_event_stream == 'in_ice'

    min_bias - Check in FilterMinBias_11 that condition_passed and prescale_passed are both true

    SMT8 - Make sure that the length of TWOfflinePulsesHLC is >= 8

    MPEFit - Check that the fit_status of MPEFit is OK, and that 40 < zenith < 70

    TriggerCheck_12 and InIceSMTTriggered - Add the TriggerCheck_12 module, which calculates InIceSMTTriggered, and check that InIceSMTTriggered is true.

  o Endpoint

    reco_endpoint - Calculate the reconstructed endpoint of the event (using the provided fit).

  o Domanalysis

    om_partition - split apart the pulses in the pulse series for cross validation when redoing the recostructions.

    dom_data - calculate the per-dom data and at it to the frame.

  o General

    General functions:

    direct_hits, hit_multiplicity, hit_statistics - Add these segments to calculate common cut variables

    move_cut_variables - Move the NDirDoms cut value calculated by direct_hits, rlogl from the provided fit parameters, and the z coordinate of the reconstructed endpoint into the top level of the frame. This is done so the cut.py script can access these values directly.

    count_hits - Iterate over the pulse series specified in options['pulse_series'], and calculate ICAnalysisHits, DCAnalysisHits, ICNHits, and DCNHits. ICAnalysisHits is the number of hits in the IC analysis region (the inner two hexagons, excluding Deep Core and string 36), and DCAnalysisHits is the number of hits in the Deep Core region, excluding strings 79 and 80. ICNHits is the number of hits outside the IC analysis region, and DCNHits is the number of hits outside the DC analysis region.

    If the -s flag (for simulation) is passed as an argument, the following two functions retrieve the truth from the data file.

    get_most_energetic - Count the number of in ice muons using the I3MCTree, and store the most energetic one, the "truth", in the frame

    get_truth_endpoint - Calculate the endpoint of the event using the "truth" muon

  o Geoanalysis

    This function looks at the geometry of events relative to the detector. The heavy lifting is done in geometry.py, which contains very general functions for simple problems in 2D computational geometry. The functions in geoanalysis mostly translate the data in the frames into something the geometry functions can work with.

    calc_dist_to_border - Calculate the shortest distance of the reconstructed event endpoint to the detector border. Endpoints outside the detector get negative distances, and events inside positive.

  o Write the output to an I3 file


Cutting: Except for a few basic cuts (min_bias, SMT8, etc.) done in the processing file, the majority of cuts are done here. In the cutting script, an arbitrary number of processed I3 files are provided as input. The cuts to make are specified in a file called cut_options.py. When cut.py is invoked, the directory containing cut_options.py must be added to the PYTHONPATH so cut.py can find it. The specified cuts are then applied, and the data is then written out to an HDF5 file for plotting (you can also write it out to a ROOT file by passing the --root flag to cut.py, but you will have to write your own plotting scripts).

  o Get the command line arguments and open the files

  o make_event_cuts - Remove the frames that do not pass all the event cuts. These cuts are defined within the 'event_cuts' dictionary in cut_options.py. It has a simple format. The keys are the names of keys in the frame, and the values define the cut to make. Ex. event_cuts['NDirDoms'] = (operator.gt, 5) means only keep frames with an NDirDoms greater than 5. Easy.

  o make_dom_cuts - Now that we have filtered out the frames that do not pass the event cuts, we can do the dom cuts. Each frame has several I3VectorDoubles that contain the data for all the doms that The cuts on the dom data are defined similarly in the 'dom_cuts' dictionary in cut_options.py.

  o Write out data to an HDF5 file.

  o write_cut_metadata - Write the cut dictionaries to the HDF5 as metadata (so we can retrieve them later to see what cuts were made).


Plotting: interpolation.py creates the final plot used to derive the in ice DOM efficiency. To use this script, you need several simulated datasets of various DOM efficiencies, as well as an experimental datafile. The idea is that the charges are placed into bins based on the corresponding reco_distances (0-20 m, 20-40 m, etc.). This is done for each dataset, and then the averaged charges for each bin are scaled down by the corresponding average charge for ______. The scaled average charges in the 20-40 m, 40-60 m, and 60-80 m bins are averaged. This charge is plotted on the y-intercept.

  o Get the command line arguments

  o Specify all the experimental errors

Quick How-To

My own submit scripts for NPX (aka Condor) are saved in /home/jgarber/submit. From there they are organized into subdirectories; for example, the IC79 scripts for processing the reconstruction events for dataset 8316 are stored in submit/ic79/process/reco/8316 (the processed i3 files are stored in a similar location: /data/user/jgarber/ic79/process/reco/8316). Here is a way to bootstrap my scripts to process your own files.

Suppose we want to process dataset 8641 with reconstructed IC79.

$ mkdir ~/8641  # a directory for the Condor submit files
$ mkdir /data/user/$USER/8641  # a directory for the processed i3 files
$ cp /home/jgarber/submit/ic79/process/reco/8316/mkprocess.py 8641
$ cd 8641

There are 200 8641 files to process, and because each Condor job runs for only 12 hours, we need a reasonable way to process all these 200 files in batches, say 15 at a time. This is what mkprocess.py does. It generates the bash scripts needed for all the batches.

$ vim mkprocess.py

Modify the bash script template in mkprocess.py so the gcd, datafile, and output directory paths point to the directories you want(in the above example, the output directory is /data/user/$USER/8641). Also change the path called by the python command so it points to the processing script you want (with the options you want).

$ python mkprocess.py 0 200 15

This generates bash scripts for processing the files 0 to 199 (we write 200 in classic computer science style) in batches of 15 files at once (eg. process_0_14.sh, process_15_29.sh, etc.)

$ ssh submitter
$ tray_ic79 (or tray_ic86 depending on what you want to process)

tray_ic79 and tray_ic86 are aliases for icetray environments in my home directory (look in /home/jgarber/.bashrc for the aliases) These environments have been modified to work with the analysis; no other icetray environments will work.

$ cd ~/8641
$ submitall .

submitall is handy script (in /home/jgarber/bin) that makes all the bash scripts in the provided directory executable (chmod +x), generates the necessary submit files for Condor, and then submits them by running condor_submit. You should now see a long list of submit information.

And there you go. Your scripts are now processing. Use condor_q to see how your jobs are doing. If they run overtime, DON'T use condor_release; it will restart your jobs, not continue them. Use condor_rm to remove the held jobs, then try resubmitting them in smaller batches, perhaps 10 instead of 15.

Global Dependencies: (for all scripts)
* Python 2.7 or 3.2+
* Numpy 1.7+

Processing Dependencies:
* IceTray

Cutting Dependencies:
* IceTray
* HDF5 1.8.11+
* Pytables 3.0+

Plotting Dependencies:
* HDF5 1.8.11+
* Pytables 3.0+
* Matplotlib 1.3+
